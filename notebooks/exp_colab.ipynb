{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT-2 KV Cache Experiments (gpt2_optim)\n",
        "\n",
        "This notebook builds and runs the KV cache experiments under `gpt2_optim/`.\n",
        "It focuses on: correctness validation, speed comparison, and profiling.\n",
        "\n",
        "Assumptions:\n",
        "- CUDA is available (Colab GPU runtime).\n",
        "- You have access to `gpt2_124M.bin` and `gpt2_tokenizer.bin` (downloaded via `llm.c` starter pack).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "Cloning the repository and building the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm -rf llm.c\n",
        "!git clone https://github.com/karpathy/llm.c.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd llm.c && chmod u+x dev/download_starter_pack.sh && ./dev/download_starter_pack.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!rm -rf gpt2_optim\n",
        "!git clone https://github.com/agridrama/gpt2_optim.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd gpt2_optim && make all GPU_COMPUTE_CAPABILITY=75 PRECISION=BF16 LLM_C_ROOT=../llm.c\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference with KV Cache Optimization\n",
        "Command line arguments:\n",
        "- `-e`: specify model path (example: `../llm.c/gpt2_124M_bf16.bin`)\n",
        "- `-tk`: specify tokenizer path (example: `../llm.c/gpt2_tokenizer.bin`)\n",
        "- `-g`: specify number of tokens to generate (example: `64`)\n",
        "- `-b`: specify batch size (example: `4`)\n",
        "- `-m`: specify sampling method (example: `0` = random sampling, `1` = greedy sampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Speed comparison (KV + kernel fusion optimizations)\n",
        "!cd gpt2_optim && ./bin/inference_gpt2optimcu \\\n",
        "  -e ../llm.c/gpt2_124M_bf16.bin \\\n",
        "  -tk ../llm.c/gpt2_tokenizer.bin \\\n",
        "  -g 64 -b 4 -m 0 -q 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Speed comparison (KV-only: other optimizations disabled)\n",
        "!cd gpt2_optim && ./bin/inference_gpt2optimcu_kvonly \\\n",
        "  -e ../llm.c/gpt2_124M_bf16.bin \\\n",
        "  -tk ../llm.c/gpt2_tokenizer.bin \\\n",
        "  -g 64 -b 4 -m 0 -q 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 検証とプロファイリング\n",
        "- `validate_kvcache_optimization`: 正確性の検証（ベースラインとの出力比較）\n",
        "- `profile_kvcache_optimization`: CUDAカーネルごとの実行時間をプロファイリング（NSYS使用）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd gpt2_optim && ./bin/validate_kvcache_optimization \\\n",
        "  -e ../llm.c/gpt2_124M_bf16.bin \\\n",
        "  -tk ../llm.c/gpt2_tokenizer.bin \\\n",
        "  -g 32 -b 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Nsight Systems (nsys), might take a few minutes\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/nsight-systems-2025.5.2_2025.5.2.266-1_amd64.deb\n",
        "!apt update\n",
        "!apt install ./nsight-systems-2025.5.2_2025.5.2.266-1_amd64.deb\n",
        "!apt --fix-broken install\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd gpt2_optim && nsys profile -t cuda,nvtx \\\n",
        "  -o prof_kvcache \\\n",
        "  ./bin/profile_kvcache_optimization \\\n",
        "    -e ../llm.c/gpt2_124M_bf16.bin \\\n",
        "    -tk ../llm.c/gpt2_tokenizer.bin \\\n",
        "    -g 128 -b 2\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
