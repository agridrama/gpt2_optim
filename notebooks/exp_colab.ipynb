{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT-2 KV Cache Experiments (gpt2_optim)\n",
        "\n",
        "This notebook builds and runs the KV cache experiments under `gpt2_optim/`.\n",
        "It focuses on: correctness validation, speed comparison, and profiling.\n",
        "\n",
        "Assumptions:\n",
        "- CUDA is available (Colab GPU runtime).\n",
        "- You have access to `gpt2_124M.bin` and `gpt2_tokenizer.bin` (downloaded via `llm.c` starter pack).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'llm.c'...\n",
            "remote: Enumerating objects: 6149, done.\u001b[K\n",
            "remote: Total 6149 (delta 0), reused 0 (delta 0), pack-reused 6149 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6149/6149), 2.25 MiB | 22.38 MiB/s, done.\n",
            "Resolving deltas: 100% (3963/3963), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf llm.c\n",
        "!git clone https://github.com/karpathy/llm.c.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded tiny_shakespeare_val.bin to /content/llm.c/dev/data/tinyshakespeare/tiny_shakespeare_val.bin\n",
            "Downloaded gpt2_tokenizer.bin to /content/llm.c/dev/../gpt2_tokenizer.bin\n",
            "Downloaded tiny_shakespeare_train.bin to /content/llm.c/dev/data/tinyshakespeare/tiny_shakespeare_train.bin\n",
            "Downloaded gpt2_124M_debug_state.bin to /content/llm.c/dev/../gpt2_124M_debug_state.bin\n",
            "Downloaded gpt2_124M_bf16.bin to /content/llm.c/dev/../gpt2_124M_bf16.bin\n",
            "Downloaded gpt2_124M.bin to /content/llm.c/dev/../gpt2_124M.bin\n",
            "Downloaded hellaswag_val.bin to /content/llm.c/dev/data/hellaswag/hellaswag_val.bin\n",
            "All files downloaded and saved in their respective directories\n"
          ]
        }
      ],
      "source": [
        "!cd llm.c && chmod u+x dev/download_starter_pack.sh && ./dev/download_starter_pack.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "!rm -rf gpt2_optim\n",
        "!git clone https://github.com/agridrama/gpt2_optim.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd gpt2_optim && make all GPU_COMPUTE_CAPABILITY=75 PRECISION=BF16 LLM_C_ROOT=../llm.c\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd gpt2_optim && ./bin/inference_gpt2optimcu \\\n",
        "  -e ../llm.c/gpt2_124M_bf16.bin \\\n",
        "  -tk ../llm.c/gpt2_tokenizer.bin \\\n",
        "  -g 64 -b 4 -m 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd gpt2_optim && ./bin/validate_kvcache_optimization -g 128 -b 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Nsight Systems (nsys)\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/nsight-systems-2025.5.2_2025.5.2.266-1_amd64.deb\n",
        "!apt update\n",
        "!apt install ./nsight-systems-2025.5.2_2025.5.2.266-1_amd64.deb\n",
        "!apt --fix-broken install\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd gpt2_optim && nsys profile -t cuda,nvtx \\\n",
        "  --capture-range=nvtx --nvtx-capture='MEASURE@*' --capture-range-end=stop-shutdown \\\n",
        "  -o prof_kvcache \\\n",
        "  ./bin/profile_kvcache_optimization\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}